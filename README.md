# Neural-Networks-Learning-MATLAB
Neural Networks backpropagation that is implemented from scratch on MATLAB

In this exercise, I implemented the backpropagation algorithm for neural networks from scratch and applied it to the task of hand-written digit recognition

Automated handwritten digit recognition is widely used today - 
from recognizing zip codes (postal codes) on mail envelopes to recognizing amounts written on bank checks.
This model trained on the MNIST dataset will show you how the methods listed above can be used for this classification task.

- **ex4.m** - combines functions below to perform a Neural Networks training
- **ex4data1.mat** - Training set of hand-written digits
- **ex4weights.mat** - Initial weights for the neural network exercise 
- **submit.m** - Submission script that sends your solutions to our servers 
- **displayData.m** - Function to help visualize the dataset
- **fmincg.m** - Function minimization routine (similar to fminunc) 
- **sigmoid.m** - Sigmoid function
- **computeNumericalGradient.m** - Numerically compute gradients 
- **checkNNGradients.m** - Function to help check gradients 
- **debugInitializeWeights.m** - Function for initializing weights 
- **predict.m** - Neural network prediction function
- **sigmoidGradient.m** - Compute the gradient of the sigmoid function
- **randInitializeWeights.m** - Randomly initialize weights
- **nnCostFunction.m** - Neural network cost function

Submited to Machine Learning Coursera course as Stanford
